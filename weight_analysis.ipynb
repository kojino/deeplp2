{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kojin/anaconda/envs/ml/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from deeplp.models.lp import LP\n",
    "from deeplp.models.data_prep import load_data, prepare_data, random_unlabel, calc_masks\n",
    "from sklearn.preprocessing import normalize\n",
    "data = 'cora'\n",
    "unlabel_prob = 0.99\n",
    "split_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_softmax(x):\n",
    "    # (1) Applies tf.nn.softmax() to a densified view of each innermost submatrix with shape [B, C], along the size-C dimension; \n",
    "    # (2) Masks out the original implicitly-zero locations; \n",
    "    # (3) Renormalizes the remaining elements.\n",
    "    graph = dense_softmax(x.toarray())\n",
    "    mask = np.zeros(graph.shape,dtype=bool) #np.ones_like(a,dtype=bool)\n",
    "    mask[[x.tocoo().row,x.tocoo().col]] = True\n",
    "    graph[~mask] = 0\n",
    "    graph_normalized = graph / np.sum(graph,axis=1,keepdims=True)\n",
    "    return csr_matrix((graph_normalized[[x.tocoo().row,x.tocoo().col]], (x.tocoo().row, x.tocoo().col)), shape=(graph.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    x_smax = x.copy()\n",
    "    x_smax.data = np.exp(x.data)\n",
    "    return normalize(x_smax,norm='l1',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lp(data,split_seed,thetas=[]):\n",
    "    true_labels, _, features, node_features, graph_sp = load_data(data,'linqs',directed=1)\n",
    "\n",
    "    labeled_indices, unlabeled_indices = \\\n",
    "        random_unlabel(true_labels,unlabel_prob,features,\n",
    "                       seed=split_seed)\n",
    "\n",
    "    labels, is_labeled = calc_masks(true_labels, labeled_indices, unlabeled_indices, logistic=0)\n",
    "\n",
    "    if len(thetas) == 0:\n",
    "        thetas = np.zeros((features.shape[0],1))\n",
    "    print(features.shape,thetas.shape)\n",
    "    weights_unnormalized = graph_sp.copy()\n",
    "    weights_unnormalized.data = np.sum(features * thetas, axis=1)      \n",
    "    weights = sparse_softmax(weights_unnormalized)\n",
    "\n",
    "    lp = LP()\n",
    "    unlabeled_pred = lp.iter_sp(labels,\n",
    "                         weights,\n",
    "                         is_labeled,\n",
    "                         100,\n",
    "                         unlabeled_indices)\n",
    "\n",
    "    y_pred = np.argmax(unlabeled_pred,axis=1)\n",
    "    y_true = np.argmax(true_labels[unlabeled_indices],axis=1)\n",
    "    log_loss = np.mean(np.sum(-1 * true_labels[unlabeled_indices] * np.log(unlabeled_pred + 0.00001),axis=1))\n",
    "    entropy = np.mean(np.sum(-1 * unlabeled_pred * np.log(unlabeled_pred + 0.00001),axis=1))\n",
    "    accuracy = np.mean(y_pred == y_true)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------cora-----------\n",
      "Loading labels...\n",
      "Loading features...\n",
      "Loading edge features...\n",
      "Weights: Asymmetric\n",
      "Loading graph...\n",
      "Done!\n",
      "(10138, 39) (10138, 1)\n"
     ]
    }
   ],
   "source": [
    "w=run_lp('cora',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('org.csv',w.data,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------cora-----------\n",
      "Loading labels...\n",
      "Loading features...\n",
      "Loading edge features...\n",
      "Weights: Asymmetric\n",
      "Loading graph...\n",
      "Done!\n",
      "(10138, 39) (39,)\n"
     ]
    }
   ],
   "source": [
    "wopt=run_lp('cora',1,np.array([ -5.21476626e-01, 1.30999064e+00, 1.24373082e-02, 1.98883004e-04\n",
    ", -4.17887459e-05, 1.07547647e-04,-3.59076425e-04,-8.14575033e-05\n",
    ", -1.27738080e-04,-2.02997719e-04, 2.54385122e-06, 3.76458658e-04\n",
    ", -4.77387524e+00, 6.37622870e-05, 1.44023055e-04,-2.15001069e-06\n",
    ",3.70156849e-05,-1.43914694e-05, 6.22029766e-05,-1.74784029e-04\n",
    ",1.16765805e-05,-1.18757892e+00, 2.55561972e+00,-1.24702696e-04\n",
    ",2.08334881e-04, 3.13223124e+00,-1.46998429e+00,-2.49465674e-01\n",
    ", -1.92462146e+00,-8.09236050e-01,-2.88095927e+00, 8.19547950e-06\n",
    ",2.67447467e-06, 3.58841899e-05, 2.54785118e-04, 1.58418421e-04\n",
    ",1.35119236e+00,-6.16346180e-01,-3.06199789e-01]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('opt.csv',wopt.data,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([ -5.21476626e-01,1.30999064e+00,1.24373082e-02,1.98883004e-04\n",
    ",-4.17887459e-05,1.07547647e-04  -3.59076425e-04  -8.14575033e-05\n",
    ",-1.27738080e-04  -2.02997719e-04,2.54385122e-06,3.76458658e-04\n",
    ",-4.77387524e+00,6.37622870e-05,1.44023055e-04  -2.15001069e-06\n",
    ", 3.70156849e-05  -1.43914694e-05,6.22029766e-05  -1.74784029e-04\n",
    ", 1.16765805e-05  -1.18757892e+00,2.55561972e+00  -1.24702696e-04\n",
    ", 2.08334881e-04,3.13223124e+00  -1.46998429e+00  -2.49465674e-01\n",
    ",-1.92462146e+00  -8.09236050e-01  -2.88095927e+00,8.19547950e-06\n",
    ", 2.67447467e-06,3.58841899e-05,2.54785118e-04,1.58418421e-04\n",
    ", 1.35119236e+00  -6.16346180e-01  -3.06199789e-01]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x,a,c):\n",
    "    return 1 / (1 + (a * x / (1 - a * x)) ** (-c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'property' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-345-a93176186528>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'property' object is not callable"
     ]
    }
   ],
   "source": [
    "g(0,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x173ced080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([g(x,1.05) for x in np.arange(0.0000001,1-0.0000001,0.001)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.constant(np.random.uniform(size=(100,1)),dtype=tf.float32)\n",
    "a = tf.Variable(1.0,dtype=tf.float32)\n",
    "c = tf.Variable(1.0,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.reduce_sum(g(x,a,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Var Variable has no gradient\n",
      "INFO:tensorflow:Var Variable_1 has no gradient\n",
      "INFO:tensorflow:Var Variable_2 has no gradient\n",
      "INFO:tensorflow:Var Variable_3 has no gradient\n",
      "INFO:tensorflow:Var Variable_4 has no gradient\n",
      "INFO:tensorflow:Var Variable_5 has no gradient\n",
      "INFO:tensorflow:Var Variable_6 has no gradient\n",
      "INFO:tensorflow:Var Variable_7 has no gradient\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer(0.001)\n",
    "update = tf.contrib.slim.learning.create_train_op(opt, optimizer,summarize_gradients=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from deeplp.models.utils import rbf_kernel\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.utils.extmath import softmax\n",
    "\n",
    "def g(x,c):\n",
    "    assert (np.any(x == 0.0) or np.any(x == 1.0))\n",
    "    return 1 / (1 + (x / (1 - x)) ** (-c))\n",
    "def iter_sp(labels, # input labels\n",
    "               weights,\n",
    "               is_labeled,\n",
    "               num_iter,\n",
    "               unlabeled_indices,\n",
    "               clamp=0,\n",
    "               laplacian=0):\n",
    "    \"\"\"Iterated solution of label propagation.\n",
    "    Input:\n",
    "        weights: weight adjacency matrix\n",
    "        is_labeled: boolean indicating labeled nodes\n",
    "        num_iter: number of iterations of propagation\n",
    "        unlabeled_indices: indices of unlabeled nodes\n",
    "    Returns:\n",
    "        label predictions for the unlabeled nodes\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # normalize T\n",
    "    Tnorm = normalize(weights, norm='l1', axis=1)\n",
    "    vals=Tnorm.tocoo().data\n",
    "    h = labels.copy()\n",
    "\n",
    "    if laplacian:\n",
    "        diagonals = np.sum(np.abs(weights),axis=1).T\n",
    "        offset = [0]\n",
    "        D = sp.sparse.diags([np.array(np.abs(weights).sum(axis=1).T)[0]], [0])\n",
    "        Dinv = sp.sparse.linalg.inv(D.tocsc())\n",
    "\n",
    "        Dinv_sqrt = np.sqrt(Dinv)\n",
    "        A = Dinv_sqrt @ weights @ Dinv_sqrt\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        if not laplacian:\n",
    "            # propagate labels\n",
    "            h = Tnorm @ h\n",
    "            # don't update labeled nodes\n",
    "            h = h * (1-is_labeled) + labels * is_labeled\n",
    "        else:\n",
    "            h = (1-laplacian) * A @ h + laplacian * labels\n",
    "\n",
    "\n",
    "        \n",
    "        clamp = g(h,1.1)\n",
    "#         print(g(np.array([0.1,0.4,0.6]),1.05))\n",
    "        h = clamp / np.sum(clamp,axis=1,keepdims=True) \n",
    "#         print()\n",
    "#         print(np.sum(h,axis=1).shape,np.sum(h,axis=1))\n",
    "        print(h[:,0])\n",
    "#         h = softmax(clamp * h)\n",
    "\n",
    "    # only return label predictions\n",
    "    return h[unlabeled_indices]\n",
    "\n",
    "\n",
    "def _tnorm(weights):\n",
    "    \"\"\"Column normalize weights\"\"\"\n",
    "    # row normalize T\n",
    "    Tnorm = weights / np.sum(weights, axis=1, keepdims=True)\n",
    "    return Tnorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  if __name__ == '__main__':\n",
      "/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in power\n",
      "  if __name__ == '__main__':\n",
      "/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in power\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14285714 0.14285714 0.14285714 ... 0.14285714 0.14285714 0.14285714]\n",
      "[0.13654171 0.14285714 0.14285714 ... 0.13033748 0.14285714 0.12144526]\n",
      "[0.13214197 0.14272175 0.14285714 ... 0.12342525 0.1419238  0.10792468]\n",
      "[0.12858872 0.14202283 0.14285714 ... 0.11269464 0.14151608 0.09326498]\n",
      "[0.12562936 0.14089362 0.14285714 ... 0.10253186 0.13986646 0.08149289]\n",
      "[0.12320024 0.13950951 0.14285714 ... 0.09066214 0.13855871 0.06971205]\n",
      "[0.12089005 0.13771912 0.14296326 ... 0.07869424 0.13602288 0.05927527]\n",
      "[0.1188323  0.13578825 0.14412493 ... 0.06638189 0.13356291 0.04935232]\n",
      "[0.11670547 0.133456   0.14514354 ... 0.05463885 0.12989137 0.04055577]\n",
      "[0.11468352 0.13101422 0.14830051 ... 0.04381762 0.12603563 0.03268835]\n",
      "[0.11249756 0.12814576 0.15110374 ... 0.03439432 0.12098132 0.02601187]\n",
      "[0.11032325 0.12514975 0.15696218 ... 0.02653168 0.11553656 0.02041885]\n",
      "[0.10792219 0.12168393 0.16249361 ... 0.0202388  0.10892864 0.01592456]\n",
      "[0.10545416 0.11804406 0.17191097 ... 0.01535736 0.10179785 0.01236769]\n",
      "[0.10270747 0.11388575 0.18135644 ... 0.0116644  0.09359964 0.00963158]\n",
      "[0.09981683 0.10949746 0.19559497 ... 0.00890818 0.08487702 0.00754   ]\n",
      "[0.09659975 0.10455146 0.21061121 ... 0.00686807 0.07535108 0.00595811]\n",
      "[0.09316439 0.09933219 0.23157068 ... 0.00535065 0.06556456 0.0047513 ]\n",
      "[0.08936247 0.09354818 0.25450002 ... 0.00421442 0.05554018 0.00382299]\n",
      "[0.08528199 0.08749058 0.28483063 ... 0.00334674 0.04584603 0.00309362]\n",
      "[0.08081701 0.08092654 0.31865815 ... 0.00267396 0.03669582 0.00250978]\n",
      "[0.07604913 0.07416723 0.36133153 ... 0.0021393  0.02853319 0.00203271]\n",
      "[0.0709262  0.06705582 0.40870248 ... 0.0017091  0.02150299 0.00163777]\n",
      "[0.06554147 0.05992512 0.4651226  ... 0.00135694 0.01575356 0.00130844]\n",
      "[0.05990701 0.05269172 0.52546206 ... 0.00106844 0.01122031 0.00103402]\n",
      "[0.05414153 0.04568903 0.59174794 ... 0.00083107 0.0077983  0.00080676]\n",
      "[4.83193974e-02 3.88809559e-02 6.57619862e-01 ... 6.37865744e-04\n",
      " 5.29791663e-03 6.20572978e-04]\n",
      "[4.25805334e-02 3.25647640e-02 7.22762616e-01 ... 4.81563911e-04\n",
      " 3.53198521e-03 4.69978016e-04]\n",
      "[3.70351661e-02 2.67134248e-02 7.81468852e-01 ... 3.57359235e-04\n",
      " 2.31681639e-03 3.50048077e-04]\n",
      "[3.18142855e-02 2.15492321e-02 8.33342550e-01 ... 2.59914692e-04\n",
      " 1.50027208e-03 2.56006191e-04]\n",
      "[2.70161283e-02 1.70170980e-02 8.75724728e-01 ... 1.85146352e-04\n",
      " 9.61427504e-04 1.83656515e-04]\n",
      "[2.27219887e-02 1.32385688e-02 9.09650520e-01 ... 1.28811797e-04\n",
      " 6.10734617e-04 1.29002870e-04]\n",
      "[1.89765432e-02 1.01119986e-02 9.35230851e-01 ... 8.74720590e-05\n",
      " 3.85036759e-04 8.86899549e-05]\n",
      "[1.57912993e-02 7.66267300e-03 9.54229255e-01 ... 5.78490410e-05\n",
      " 2.40856144e-04 5.96040947e-05]\n",
      "[1.31496130e-02 5.75510940e-03 9.67763295e-01 ... 3.72678657e-05\n",
      " 1.49577707e-04 3.92209674e-05]\n",
      "[1.10075931e-02 4.35444996e-03 9.77333499e-01 ... 2.33767915e-05\n",
      " 9.21948122e-05 2.52925211e-05]\n",
      "[9.31065058e-03 3.32463473e-03 9.83938793e-01 ... 1.43185589e-05\n",
      " 5.65508652e-05 1.60793892e-05]\n",
      "[7.99180648e-03 2.61570302e-03 9.88508185e-01 ... 8.59650009e-06\n",
      " 3.46319983e-05 1.01364304e-05]\n",
      "[6.98870654e-03 2.11915330e-03 9.91645142e-01 ... 5.10494376e-06\n",
      " 2.13555207e-05 6.42155651e-06]\n",
      "[6.23807479e-03 1.79871109e-03 9.93824059e-01 ... 3.03602294e-06\n",
      " 1.33945510e-05 4.14326753e-06]\n",
      "[5.68852881e-03 1.58154420e-03 9.95344585e-01 ... 1.84404239e-06\n",
      " 8.67928594e-06 2.77891903e-06]\n",
      "[5.29227685e-03 1.45153127e-03 9.96423301e-01 ... 1.16959464e-06\n",
      " 5.89320231e-06 1.96671839e-06]\n",
      "[5.01390907e-03 1.36427856e-03 9.97196029e-01 ... 7.92625765e-07\n",
      " 4.25009987e-06 1.48860226e-06]\n",
      "[4.82149268e-03 1.31808530e-03 9.97758477e-01 ... 5.81515572e-07\n",
      " 3.26982978e-06 1.20407372e-06]\n",
      "[4.69300635e-03 1.28615257e-03 9.98171874e-01 ... 4.62268013e-07\n",
      " 2.67794331e-06 1.03436644e-06]\n",
      "[4.60827521e-03 1.27387519e-03 9.98479889e-01 ... 3.93216577e-07\n",
      " 2.31021051e-06 9.29706219e-07]\n",
      "[4.55431833e-03 1.26404435e-03 9.98711308e-01 ... 3.51894866e-07\n",
      " 2.07474379e-06 8.63247378e-07]\n",
      "[4.51850529e-03 1.26435081e-03 9.98887126e-01 ... 3.25604455e-07\n",
      " 1.91524497e-06 8.17236514e-07]\n",
      "[4.49343684e-03 1.26274564e-03 9.99021459e-01 ... 3.07464538e-07\n",
      " 1.80035801e-06 7.82396169e-07]\n",
      "[4.47112338e-03 1.26692124e-03 9.99124827e-01 ... 2.93369534e-07\n",
      " 1.70967197e-06 7.52039809e-07]\n",
      "[4.44764736e-03 1.26784681e-03 9.99204333e-01 ... 2.81106684e-07\n",
      " 1.63225159e-06 7.23069162e-07]\n",
      "[4.41802607e-03 1.27237589e-03 9.99265427e-01 ... 2.69304651e-07\n",
      " 1.56040316e-06 6.93072767e-07]\n",
      "[4.38073098e-03 1.27347269e-03 9.99311749e-01 ... 2.57351737e-07\n",
      " 1.49076418e-06 6.61504968e-07]\n",
      "[4.33296691e-03 1.27696813e-03 9.99346237e-01 ... 2.44929174e-07\n",
      " 1.42072974e-06 6.27947958e-07]\n",
      "[4.27501606e-03 1.27728022e-03 9.99370788e-01 ... 2.32093784e-07\n",
      " 1.35009569e-06 5.93087236e-07]\n",
      "[4.20580462e-03 1.27927773e-03 9.99387090e-01 ... 2.18990913e-07\n",
      " 1.27849970e-06 5.57474739e-07]\n",
      "[4.12695837e-03 1.27849615e-03 9.99396157e-01 ... 2.05943740e-07\n",
      " 1.20703483e-06 5.22254202e-07]\n",
      "[4.03868255e-03 1.27897073e-03 9.99399051e-01 ... 1.93234789e-07\n",
      " 1.13618976e-06 4.88199852e-07]\n",
      "[3.94338265e-03 1.27711512e-03 9.99396338e-01 ... 1.81184411e-07\n",
      " 1.06729846e-06 4.56279205e-07]\n",
      "[3.84200858e-03 1.27626308e-03 9.99388771e-01 ... 1.69987274e-07\n",
      " 1.00087108e-06 4.26931962e-07]\n",
      "[3.73711915e-03 1.27352390e-03 9.99376696e-01 ... 1.59800873e-07\n",
      " 9.37885446e-07 4.00582753e-07]\n",
      "[3.62987356e-03 1.27164668e-03 9.99360707e-01 ... 1.50642215e-07\n",
      " 8.78503708e-07 3.77153695e-07]\n",
      "[3.52247448e-03 1.26829400e-03 9.99341053e-01 ... 1.42492547e-07\n",
      " 8.23199191e-07 3.56561672e-07]\n",
      "[3.41590642e-03 1.26572915e-03 9.99318238e-01 ... 1.35238639e-07\n",
      " 7.71809245e-07 3.38395782e-07]\n",
      "[3.31175699e-03 1.26205555e-03 9.99292473e-01 ... 1.28774091e-07\n",
      " 7.24450238e-07 3.22352596e-07]\n",
      "[3.21066624e-03 1.25913163e-03 9.99264200e-01 ... 1.22956263e-07\n",
      " 6.80817540e-07 3.07983631e-07]\n",
      "[3.11359047e-03 1.25541068e-03 9.99233620e-01 ... 1.17683636e-07\n",
      " 6.40863644e-07 2.95024530e-07]\n",
      "[3.02082472e-03 1.25241129e-03 9.99201115e-01 ... 1.12851054e-07\n",
      " 6.04275232e-07 2.83160993e-07]\n",
      "[2.93282110e-03 1.24886251e-03 9.99166882e-01 ... 1.08400214e-07\n",
      " 5.70944475e-07 2.72258193e-07]\n",
      "[2.84961311e-03 1.24599656e-03 9.99131247e-01 ... 1.04273529e-07\n",
      " 5.40585297e-07 2.62144959e-07]\n",
      "[2.77131453e-03 1.24276050e-03 9.99094395e-01 ... 1.00447653e-07\n",
      " 5.13056354e-07 2.52780498e-07]\n",
      "[2.69779504e-03 1.24014755e-03 9.99056594e-01 ... 9.68930988e-08\n",
      " 4.88091132e-07 2.44073326e-07]\n",
      "[2.62897033e-03 1.23728069e-03 9.99018013e-01 ... 9.36007368e-08\n",
      " 4.65523990e-07 2.36016502e-07]\n",
      "[2.56462287e-03 1.23495783e-03 9.98978866e-01 ... 9.05506298e-08\n",
      " 4.45105908e-07 2.28546045e-07]\n",
      "[2.50456571e-03 1.23244834e-03 9.98939299e-01 ... 8.77352419e-08\n",
      " 4.26664642e-07 2.21656001e-07]\n",
      "[2.44854386e-03 1.23039386e-03 9.98899479e-01 ... 8.51361251e-08\n",
      " 4.09977673e-07 2.15288784e-07]\n",
      "[2.39632628e-03 1.22818822e-03 9.98859524e-01 ... 8.27439007e-08\n",
      " 3.94885051e-07 2.09431620e-07]\n",
      "[2.34765158e-03 1.22634930e-03 9.98819564e-01 ... 8.05403267e-08\n",
      " 3.81198784e-07 2.04029922e-07]\n",
      "[2.30228047e-03 1.22437722e-03 9.98779692e-01 ... 7.85147935e-08\n",
      " 3.68782186e-07 1.99066236e-07]\n",
      "[2.25996559e-03 1.22269161e-03 9.98740003e-01 ... 7.66500815e-08\n",
      " 3.57483185e-07 1.94490585e-07]\n",
      "[2.22048146e-03 1.22088266e-03 9.98700571e-01 ... 7.49356216e-08\n",
      " 3.47190885e-07 1.90284282e-07]\n",
      "[2.18360684e-03 1.21929113e-03 9.98661466e-01 ... 7.33560116e-08\n",
      " 3.37785401e-07 1.86403439e-07]\n",
      "[2.14914132e-03 1.21758270e-03 9.98622739e-01 ... 7.19015682e-08\n",
      " 3.29179250e-07 1.82830392e-07]\n",
      "[2.11689418e-03 1.21603416e-03 9.98584441e-01 ... 7.05590394e-08\n",
      " 3.21279007e-07 1.79527746e-07]\n",
      "[2.08669318e-03 1.21437383e-03 9.98546609e-01 ... 6.93199967e-08\n",
      " 3.14016512e-07 1.76479895e-07]\n",
      "[2.05837722e-03 1.21282620e-03 9.98509274e-01 ... 6.81733203e-08\n",
      " 3.07319139e-07 1.73655588e-07]\n",
      "[2.03180074e-03 1.21117135e-03 9.98472461e-01 ... 6.71119022e-08\n",
      " 3.01133959e-07 1.71041556e-07]\n",
      "[2.00682888e-03 1.20959095e-03 9.98436190e-01 ... 6.61265553e-08\n",
      " 2.95404368e-07 1.68611992e-07]\n",
      "[1.98333952e-03 1.20790773e-03 9.98400474e-01 ... 6.52113996e-08\n",
      " 2.90089185e-07 1.66355855e-07]\n",
      "[1.96122004e-03 1.20626848e-03 9.98365323e-01 ... 6.43589127e-08\n",
      " 2.85144070e-07 1.64251982e-07]\n",
      "[1.94036813e-03 1.20453109e-03 9.98330740e-01 ... 6.35642848e-08\n",
      " 2.80536833e-07 1.62291299e-07]\n",
      "[1.92068962e-03 1.20281413e-03 9.98296730e-01 ... 6.28213866e-08\n",
      " 2.76232519e-07 1.60456526e-07]\n",
      "[1.90209863e-03 1.20100455e-03 9.98263291e-01 ... 6.21263080e-08\n",
      " 2.72205822e-07 1.58740255e-07]\n",
      "[1.88451606e-03 1.19919820e-03 9.98230419e-01 ... 6.14740689e-08\n",
      " 2.68429015e-07 1.57128422e-07]\n",
      "[1.86786948e-03 1.19730589e-03 9.98198109e-01 ... 6.08615028e-08\n",
      " 2.64882080e-07 1.55615007e-07]\n",
      "[1.85209208e-03 1.19540524e-03 9.98166353e-01 ... 6.02845716e-08\n",
      " 2.61542896e-07 1.54188594e-07]\n",
      "[1.83712237e-03 1.19342650e-03 9.98135144e-01 ... 5.97407167e-08\n",
      " 2.58395536e-07 1.52844304e-07]\n",
      "[1.82290357e-03 1.19143254e-03 9.98104471e-01 ... 5.92266681e-08\n",
      " 2.55422254e-07 1.51572892e-07]\n",
      "[1.80938323e-03 1.18936927e-03 9.98074322e-01 ... 5.87403592e-08\n",
      " 2.52610295e-07 1.50370401e-07]\n",
      "[1.79651284e-03 1.18728760e-03 9.98044686e-01 ... 5.82791417e-08\n",
      " 2.49945344e-07 1.49229351e-07]\n"
     ]
    }
   ],
   "source": [
    "# true_labels, _, features, _, \\\n",
    "# graph_sp, _ = load_data(data,directed=1)\n",
    "\n",
    "# labeled_indices, unlabeled_indices = \\\n",
    "#     random_unlabel(true_labels,unlabel_prob,features,\n",
    "#                    seed=split_seed)\n",
    "\n",
    "# labels, is_labeled = calc_masks(true_labels, labeled_indices, unlabeled_indices, logistic=0)\n",
    "\n",
    "# if len(thetas) == 0:\n",
    "#     thetas = np.zeros((features.shape[0],1))\n",
    "\n",
    "# weights_unnormalized = graph_sp.copy()\n",
    "# weights_unnormalized.data = np.sum(features * thetas, axis=1)    \n",
    "\n",
    "# weights = sparse_softmax(weights_unnormalized)\n",
    "\n",
    "unlabeled_pred = iter_sp(labels,\n",
    "                     weights,\n",
    "                     is_labeled,\n",
    "                     100,\n",
    "                     unlabeled_indices)\n",
    "\n",
    "\n",
    "y_pred = np.argmax(unlabeled_pred,axis=1)\n",
    "y_true = np.argmax(true_labels[unlabeled_indices],axis=1)\n",
    "log_loss = np.mean(np.sum(-1 * true_labels[unlabeled_indices] * np.log(unlabeled_pred + 0.00001),axis=1))\n",
    "entropy = np.mean(np.sum(-1 * unlabeled_pred * np.log(unlabeled_pred + 0.00001),axis=1))\n",
    "accuracy = np.mean(y_pred == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6707317073170732"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
